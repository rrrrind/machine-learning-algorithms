{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_splitx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datasetの使い方は[こちら](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = iris.data\n",
    "targets = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names  = iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "説明変数：['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "目的変数：['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(\"説明変数：{}\".format(feature_names))\n",
    "print(\"目的変数：{}\".format(target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trainとtestに分ける"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_test_splitの使い方は[こちら](https://docs.pyq.jp/python/machine_learning/tips/train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットを訓練データとテストデータに分ける\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(iris.data, iris.target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARTの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量と条件分岐の閾値の決定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini係数の算出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "決定木は『不純度』を用いることで分岐条件や特徴量を選択する．\n",
    "不純度とは，ノード分岐の条件や選択した特徴量(説明変数)によって，ノードに分岐したサンプルのクラスがどれだけ散らばるかを表す指標の1つである．\n",
    "分岐した際に，クラスがばらけることなく，あるノードに1種類のクラスだけが分類された場合(きれいに分割できた場合)，**そのノードの不純度は0となる**．\n",
    "不純度を算出する方法は『交差エントロピー』と『Gini係数』があり，CARTの場合は『Gini係数』を用いることで不純度の計算を行う．\n",
    "Gini係数は，ノード$t$におけるクラス$C_{i}$の割合を$P^{2}(C_{i}|t)$とすると，\n",
    "$$\n",
    "1 - \\sum_{i=1}^{K}P^{2}(C_{i}|t),\n",
    "$$\n",
    "で算出することができる．\n",
    "Gini係数は，ある条件に対して\"Yes\"と\"No\"の，2つ場合に対して求める必要がある(後にGini不純度を計算する必要があるため)．\n",
    "詳しくは[こちら](https://hktech.hatenablog.com/entry/2018/10/05/004235)．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini不純度の算出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini不純度とは，分岐条件毎に算出していた『Gini係数』を用いることで，その分岐条件自体を評価するための指標である．Gini不純度を用いることで，その特徴量における最も分類精度が高い分岐条件を求めることができるので，全特徴量のGini不純度を比較することで，分岐条件だけでなく分類精度が最も高くなる特徴量を選出することも可能となる．ある特徴量における分岐条件のGini不純度は，ノードの集合を$\\{\\mathrm{yes},\\mathrm{no}\\}$，1つ前のノードのデータ数を$A$，各ノードのデータ数を$a$とすると，\n",
    "$$\n",
    "\\sum_{n \\in \\{\\mathrm{yes},\\mathrm{no}\\}}\\frac{a_n}{A} \\times \\mathrm{Gini}(n),\n",
    "$$\n",
    "で算出することができる．ここで$\\mathrm{Gini}(n)$とは，yes or no のノードのGini係数である．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利得(gain)の算出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利得(gain)とは，分岐前のGini不純度から分岐後のGini不純度を引いた値である．これは分岐後のGini不純度が大きく下がっていれば，それだけその分岐が有効であったことがわかるので，利得が大きければ大きいほどその分岐が重要だということが示される．また各特徴量の分岐の利得を比較すれば，最適な特徴量空間を選出することも可能となる．本来であれば利得を用いて特徴量と閾値を算出すべきだが，今回は利得ではなく各特徴量のGini不純度を比較することでそれらを選出する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cart(object):\n",
    "    \"\"\"\n",
    "    これは，run()を実行すると\"Gini不純度が最も低かった特徴量のindex\"と\"その時の閾値\"を渡してくれるクラスである．\n",
    "    今回はirisのデータセットを用いているが，入力データやターゲットを変えていただければ\n",
    "    別のsklearnのデータセットなどでも適用することが可能である．\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.inputs = None\n",
    "        self.targets = None\n",
    "        self.feature_names = None\n",
    "        self.target_names = None\n",
    "\n",
    "        self.gini = None\n",
    "        self.node = None\n",
    "        self.yes_num = None\n",
    "        self.no_num = None\n",
    "        \n",
    "        self.impurity = None\n",
    "        \n",
    "        self.min_imp = None\n",
    "        self.min_gini = None\n",
    "        self.threshold = None\n",
    "        \n",
    "    \n",
    "    def calc_gini(self,input_1d):\n",
    "        \"\"\"\n",
    "        ある特徴量に対する全データのGini係数を算出する(2.1参照)．\n",
    "        \n",
    "        Parameters\n",
    "        -------------------------------------------\n",
    "        input_1d : ndarray\n",
    "            ある特徴量における現在いるノードの全データである\n",
    "        -------------------------------------------\n",
    "        \"\"\"\n",
    "        self.gini = np.zeros((len(input_1d),2))\n",
    "        \n",
    "        for i, data in enumerate(input_1d):\n",
    "            branch = input_1d > data\n",
    "            self.node = np.zeros(2)\n",
    "            self.yes_num = np.sum(branch)\n",
    "            self.no_num  = np.sum(np.logical_not(branch))            \n",
    "            if self.yes_num == 0:\n",
    "                self.yes_num = 1e-8\n",
    "            if self.no_num == 0:\n",
    "                self.no_num = 1e-8\n",
    "                     \n",
    "            for c in range(len(self.target_names)):\n",
    "                self.node[0] += np.square(np.sum(self.targets[branch]==c) / self.yes_num)\n",
    "                self.node[1] += np.square(np.sum(self.targets[np.logical_not(branch)]==c) / self.no_num)\n",
    "            for j in range(2):\n",
    "                self.gini[i,j] = 1 - self.node[j]\n",
    "    \n",
    "    \n",
    "    def calc_impurity(self,input_1d):\n",
    "        \"\"\"\n",
    "        ある特徴量に対する全データのGini係数から，\n",
    "        分岐の良し悪しを評価するGini不純度を算出し，最小のGini不純度を獲得する(2.2参照)．\n",
    "        最小のGini不純度を獲得することで，最適な分岐条件と特徴量を決定することが可能となる(2.3参照)．\n",
    "        \n",
    "        Parameters\n",
    "        -------------------------------------------\n",
    "        input_1d : ndarray\n",
    "            ある特徴量における現在いるノードの全データである\n",
    "        -------------------------------------------\n",
    "        \"\"\"\n",
    "        self.calc_gini(input_1d)\n",
    "        \n",
    "        self.impurity = np.zeros(len(self.gini))\n",
    "        self.impurity = self.gini[:,0] * (self.yes_num / (self.yes_num + self.no_num)) + \\\n",
    "                        self.gini[:,1] * (self.no_num  / (self.yes_num + self.no_num))\n",
    "    \n",
    "    \n",
    "    def best_impurity(self):\n",
    "        \"\"\"\n",
    "        ある特徴量での，Gini不純度が最も小さい時の値とそのindexを返す．\n",
    "        \n",
    "        Returns\n",
    "        -------------------------------------------\n",
    "        np.min(self.impurity) : int\n",
    "            ある特徴量における入力された全データの中でGini不純度が最も小さい時の値．\n",
    "        np.argmin(self.impurity) : int\n",
    "            ある特徴量における入力された全データの中でGini不純度が最も小さい時のindex．\n",
    "        -------------------------------------------\n",
    "        \"\"\"\n",
    "        return np.min(self.impurity), np.argmin(self.impurity)\n",
    "    \n",
    "    \n",
    "    def best_feature(self):\n",
    "        \"\"\"\n",
    "        全特徴量のGini不純度を計算し比較することで，\n",
    "        クラスが最も綺麗に分かれる特徴量と分岐の閾値を獲得する(2.3参照)．\n",
    "        \n",
    "        Returns\n",
    "        -------------------------------------------\n",
    "        self.min_gini[np.argmin(self.min_imp[:,0])] : int\n",
    "            全特徴量の中でGini不純度が最も小さい特徴量のGini係数\n",
    "        np.argmin(self.min_imp[:,0]) : int\n",
    "            全特徴量の中でGini不純度が最も小さい特徴量のindex．\n",
    "        self.threshold : float\n",
    "            全特徴量の中でGini不純度が最も小さい特徴量の閾値．\n",
    "        -------------------------------------------\n",
    "        \"\"\"\n",
    "        self.min_imp = np.zeros((len(self.inputs[0]),2))\n",
    "        self.threshold = 0\n",
    "        \n",
    "        for i in range(len(self.inputs[0])):\n",
    "            self.calc_impurity(self.inputs[:,i])\n",
    "            self.min_imp[i,0], self.min_imp[i,1] = self.best_impurity()\n",
    "        \n",
    "        self.threshold = self.inputs[self.min_imp[np.argmin(self.min_imp[:,0]),1].astype('int64'), \\\n",
    "                                     np.argmin(self.min_imp[:,0])]\n",
    "        \n",
    "        return np.min(self.min_imp[:,0]), np.argmin(self.min_imp[:,0]), self.threshold\n",
    "        \n",
    "    \n",
    "    def search_best_split(self,inputs,targets,feature_names,target_names):\n",
    "        \"\"\"\n",
    "        Gini係数とGini不純度の計算を行う．\n",
    "        最終的に，クラスが最も綺麗に分かれる特徴量と分岐の閾値を獲得する．\n",
    "\n",
    "        Parameters\n",
    "        -------------------------------------------\n",
    "        inputs : ndarray\n",
    "            全特徴量におけるデータの総数．\n",
    "            irisでは，1回目は[105,4]のリストが入るが，\n",
    "            2回目以降はそのノードにおけるデータの総数となる．\n",
    "        targets : ndarray\n",
    "            全特徴量における教師ラベル．\n",
    "            irisでは，1回目は105のサイズだが，\n",
    "            2回目以降はそのノードにおけるデータの総数がサイズとなる．\n",
    "        feature_names : list\n",
    "            特徴量の名前.\n",
    "            irisでは[4,0]のリストを代入する\n",
    "        target_names : ndarray\n",
    "            クラスの名前．\n",
    "            irisでは[3,0]のリストを代入する\n",
    "        -------------------------------------------\n",
    "        \n",
    "        Returns\n",
    "        -------------------------------------------\n",
    "        self.selc_feature() : float, int, float\n",
    "            全特徴量の中でGini不純度が最も小さい特徴量のGini不純度\n",
    "            全特徴量の中で最もGini不純度が小さい特徴量のindex\n",
    "            その時の特徴量の分岐の閾値．\n",
    "        -------------------------------------------\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.feature_names = feature_names\n",
    "        self.target_names = target_names\n",
    "                \n",
    "        return self.best_feature()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 決定木の構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 決定木のノードの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeNode(object):\n",
    "    def __init__(self,inputs,targets,feature_names,target_names,algorithm,max_depth):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.feature_names = feature_names\n",
    "        self.target_names = target_names\n",
    "        self.algorithm = algorithm\n",
    "        \n",
    "        self.f_idx = None\n",
    "        self.impurity = None\n",
    "        self.threshold = None\n",
    "        \n",
    "        self.label = None\n",
    "        self.depth = None\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        self.left = None\n",
    "        self.right = None\n",
    "    \n",
    "    def split(self,depth):\n",
    "        self.depth = depth\n",
    "        if len(self.targets) != 0:\n",
    "            self.label = np.argmax(np.bincount(self.targets))\n",
    "        if len(self.inputs) == 0 :\n",
    "            return\n",
    "        \n",
    "        self.impurity, self.f_idx, self.threshold = \\\n",
    "        self.algorithm.search_best_split(self.inputs,self.targets,self.feature_names,self.target_names)\n",
    "        \n",
    "        print(\"深さ:{}, 最適な特徴量:{}, 分岐条件の閾値:{}, このノードのクラス:{}\".format( \\\n",
    "               self.depth, self.feature_names[self.f_idx], self.threshold, self.target_names[self.label]))\n",
    "        \n",
    "        if self.depth==self.max_depth or self.impurity == 0.0 :\n",
    "            return\n",
    "        \n",
    "        left_idx = self.inputs[:,self.f_idx] <= self.threshold\n",
    "        right_idx = self.inputs[:,self.f_idx] > self.threshold\n",
    "        \n",
    "        self.left = DecisionTreeNode(self.inputs[left_idx],self.targets[left_idx], \\\n",
    "                                     self.feature_names,self.target_names,self.algorithm,self.max_depth)\n",
    "        self.left.split(self.depth+1)\n",
    "        \n",
    "        self.right = DecisionTreeNode(self.inputs[right_idx],self.targets[right_idx], \\\n",
    "                                      self.feature_names,self.target_names,self.algorithm,self.max_depth)\n",
    "        self.right.split(self.depth+1)\n",
    "        \n",
    "    def predict(self,test_data):\n",
    "        if self.depth == self.max_depth or self.impurity == 0.0 or len(self.inputs) == 0:\n",
    "            return self.label\n",
    "        \n",
    "        if test_data[self.f_idx] <= self.threshold :\n",
    "            return self.left.predict(test_data)\n",
    "        elif test_data[self.f_idx] > self.threshold :\n",
    "            return self.right.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 決定木の学習とテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier(object):\n",
    "    def __init__(self,inputs,targets,feature_names,target_names,algorithm,max_depth=3):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.feature_names = feature_names\n",
    "        self.target_names = target_names\n",
    "        self.algorithm = algorithm\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "        \n",
    "    def learning(self):\n",
    "        self.tree = DecisionTreeNode(self.inputs,self.targets, \\\n",
    "                                     self.feature_names,self.target_names,self.algorithm,self.max_depth)\n",
    "        self.tree.split(0)\n",
    "        \n",
    "    def predict(self,test_data):\n",
    "        pred = []\n",
    "        for data in test_data:\n",
    "            pred.append(self.tree.predict(data))\n",
    "        return np.array(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "深さ:0, 最適な特徴量:sepal length (cm), 分岐条件の閾値:4.8, このノードのクラス:virginica\n",
      "深さ:1, 最適な特徴量:sepal length (cm), 分岐条件の閾値:4.4, このノードのクラス:setosa\n",
      "深さ:1, 最適な特徴量:sepal width (cm), 分岐条件の閾値:2.0, このノードのクラス:virginica\n",
      "深さ:2, 最適な特徴量:sepal length (cm), 分岐条件の閾値:5.0, このノードのクラス:versicolor\n",
      "深さ:3, 最適な特徴量:sepal length (cm), 分岐条件の閾値:5.0, このノードのクラス:versicolor\n",
      "深さ:4, 最適な特徴量:sepal length (cm), 分岐条件の閾値:5.0, このノードのクラス:versicolor\n",
      "深さ:2, 最適な特徴量:petal width (cm), 分岐条件の閾値:0.6, このノードのクラス:virginica\n",
      "深さ:3, 最適な特徴量:sepal length (cm), 分岐条件の閾値:5.7, このノードのクラス:setosa\n",
      "深さ:3, 最適な特徴量:petal width (cm), 分岐条件の閾値:1.7, このノードのクラス:virginica\n",
      "深さ:4, 最適な特徴量:petal width (cm), 分岐条件の閾値:1.0, このノードのクラス:versicolor\n",
      "深さ:4, 最適な特徴量:sepal length (cm), 分岐条件の閾値:5.6, このノードのクラス:virginica\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(X_train,y_train,feature_names,target_names,Cart(),4)\n",
    "clf.learning()\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy : 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "score = sum(y_pred == y_test) / len(y_test)\n",
    "print(\"classification accuracy : {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考文献"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [sklearn.datasets.load_iris](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)\n",
    "- [train_test_split関数でデータ分割](https://docs.pyq.jp/python/machine_learning/tips/train_test_split.html)\n",
    "- [Pythonで決定木分類器をフルスクラッチで実装してみた](https://hktech.hatenablog.com/entry/2018/10/05/004235)\n",
    "- [[入門]初心者の初心者による初心者のための決定木分析](https://qiita.com/3000manJPY/items/ef7495960f472ec14377)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
